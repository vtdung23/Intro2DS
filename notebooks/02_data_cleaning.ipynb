{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab08886",
   "metadata": {},
   "source": [
    "## Giai đoạn 1: Phân tích và Lọc dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e089c51",
   "metadata": {},
   "source": [
    "Cell này kiểm tra số records của dataset và số features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d1c433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "THỐNG KÊ NULL VALUES VÀ GIÁ TRỊ 0 TRONG DATASET\n",
      "================================================================================\n",
      "\n",
      "Tổng số dòng: 100000\n",
      "Tổng số cột: 29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Đọc dataset\n",
    "df = pd.read_csv('../data/raw/raw_data.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"THỐNG KÊ NULL VALUES VÀ GIÁ TRỊ 0 TRONG DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTổng số dòng: {len(df)}\")\n",
    "print(f\"Tổng số cột: {len(df.columns)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d28e6a6",
   "metadata": {},
   "source": [
    "Cell này kiểm tra null của các cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c04814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NHÓM 1: CÁC CỘT CÓ NULL VALUES\n",
      "================================================================================\n",
      "\n",
      "Tổng số cột có NULL: 18\n",
      "\n",
      "                 Cột  Số lượng NULL  Phần trăm (%)\n",
      "        instagram_id          97335          97.34\n",
      "          twitter_id          97281          97.28\n",
      "         facebook_id          95102          95.10\n",
      "     collection_name          94514          94.51\n",
      "       collection_id          94514          94.51\n",
      "    certification_US          89874          89.87\n",
      "             tagline          80411          80.41\n",
      "         trailer_key          75150          75.15\n",
      "            keywords          62585          62.58\n",
      "production_companies          42134          42.13\n",
      "production_countries          25871          25.87\n",
      "             imdb_id          24287          24.29\n",
      "    spoken_languages          21821          21.82\n",
      "              genres          15963          15.96\n",
      "           cast_top5          13698          13.70\n",
      "            overview           8932           8.93\n",
      "           directors           8477           8.48\n",
      "        release_date              1           0.00\n",
      "\n",
      "Cột                                       NULL          %\n",
      "--------------------------------------------------------\n",
      "cast_top5                               13,698     13.70%\n",
      "certification_US                        89,874     89.87%\n",
      "collection_id                           94,514     94.51%\n",
      "collection_name                         94,514     94.51%\n",
      "directors                                8,477      8.48%\n",
      "facebook_id                             95,102     95.10%\n",
      "genres                                  15,963     15.96%\n",
      "imdb_id                                 24,287     24.29%\n",
      "instagram_id                            97,335     97.34%\n",
      "keywords                                62,585     62.58%\n",
      "overview                                 8,932      8.93%\n",
      "production_companies                    42,134     42.13%\n",
      "production_countries                    25,871     25.87%\n",
      "release_date                                 1      0.00%\n",
      "spoken_languages                        21,821     21.82%\n",
      "tagline                                 80,411     80.41%\n",
      "trailer_key                             75,150     75.15%\n",
      "twitter_id                              97,281     97.28%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra null values trong từng cột\n",
    "null_counts = df.isnull().sum()\n",
    "null_percentages = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "\n",
    "# Lọc các cột có null values\n",
    "columns_with_nulls = null_counts[null_counts > 0]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NHÓM 1: CÁC CỘT CÓ NULL VALUES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(columns_with_nulls) > 0:\n",
    "    null_df = pd.DataFrame({\n",
    "        'Cột': columns_with_nulls.index,\n",
    "        'Số lượng NULL': columns_with_nulls.values,\n",
    "        'Phần trăm (%)': [null_percentages[col] for col in columns_with_nulls.index]\n",
    "    })\n",
    "    null_df = null_df.sort_values('Số lượng NULL', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nTổng số cột có NULL: {len(columns_with_nulls)}\\n\")\n",
    "    print(null_df.to_string(index=False))\n",
    "    print(f\"\\n{'Cột':<30} {'NULL':>15} {'%':>10}\")\n",
    "    print(\"-\"*56)\n",
    "    for col in columns_with_nulls.index:\n",
    "        print(f\"{col:<30} {null_counts[col]:>15,} {null_percentages[col]:>9.2f}%\")\n",
    "else:\n",
    "    print(\"\\n✓ Không có cột nào chứa NULL values\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e086a1d",
   "metadata": {},
   "source": [
    "Cell này kiểm tra giá trị 0 của các cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f1ad42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NHÓM 2: CÁC CỘT CÓ GIÁ TRỊ 0\n",
      "================================================================================\n",
      "(Chỉ kiểm tra các cột số)\n",
      "\n",
      "Tổng số cột có giá trị 0: 6\n",
      "\n",
      "         Cột  Số lượng giá trị 0  Phần trăm (%)\n",
      "     revenue               94799          94.80\n",
      "      budget               92433          92.43\n",
      "vote_average               41473          41.47\n",
      "  vote_count               41409          41.41\n",
      "     runtime               13086          13.09\n",
      "  popularity                 987           0.99\n",
      "\n",
      "Cột                                  Giá trị 0          %\n",
      "--------------------------------------------------------\n",
      "revenue                                 94,799     94.80%\n",
      "budget                                  92,433     92.43%\n",
      "vote_average                            41,473     41.47%\n",
      "vote_count                              41,409     41.41%\n",
      "runtime                                 13,086     13.09%\n",
      "popularity                                 987      0.99%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra giá trị 0 trong từng cột (chỉ cho cột số)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "zero_counts = {}\n",
    "zero_percentages = {}\n",
    "\n",
    "for col in numeric_cols:\n",
    "    zero_count = (df[col] == 0).sum()\n",
    "    if zero_count > 0:\n",
    "        zero_counts[col] = zero_count\n",
    "        zero_percentages[col] = round((zero_count / len(df) * 100), 2)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NHÓM 2: CÁC CỘT CÓ GIÁ TRỊ 0\")\n",
    "print(\"=\"*80)\n",
    "print(\"(Chỉ kiểm tra các cột số)\\n\")\n",
    "\n",
    "if len(zero_counts) > 0:\n",
    "    zero_df = pd.DataFrame({\n",
    "        'Cột': list(zero_counts.keys()),\n",
    "        'Số lượng giá trị 0': list(zero_counts.values()),\n",
    "        'Phần trăm (%)': [zero_percentages[col] for col in zero_counts.keys()]\n",
    "    })\n",
    "    zero_df = zero_df.sort_values('Số lượng giá trị 0', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Tổng số cột có giá trị 0: {len(zero_counts)}\\n\")\n",
    "    print(zero_df.to_string(index=False))\n",
    "    print(f\"\\n{'Cột':<30} {'Giá trị 0':>15} {'%':>10}\")\n",
    "    print(\"-\"*56)\n",
    "    for col in sorted(zero_counts.keys(), key=lambda x: zero_counts[x], reverse=True):\n",
    "        print(f\"{col:<30} {zero_counts[col]:>15,} {zero_percentages[col]:>9.2f}%\")\n",
    "else:\n",
    "    print(\"\\n✓ Không có cột số nào chứa giá trị 0\")\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3f307",
   "metadata": {},
   "source": [
    "Cell này để xóa các dòng có output target = 0, vì nó không có giá trị huấn luyện đối với bài toán supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d198ae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "XÓA CÁC RECORDS CÓ vote_average = 0\n",
      "================================================================================\n",
      "\n",
      "Số dòng ban đầu: 100,000\n",
      "Số records có vote_average = 0: 41,473 (41.47%)\n",
      "Số dòng sau khi xóa: 58,527\n",
      "Số dòng đã xóa: 41,473\n",
      "\n",
      "Đã lưu file mới: preprocessed_data_v2.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Xóa các records có vote_average = 0 và lưu file mới\n",
    "print(\"=\"*80)\n",
    "print(\"XÓA CÁC RECORDS CÓ vote_average = 0\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Đọc lại file gốc\n",
    "df_original = pd.read_csv('../data/raw/raw_data.csv')\n",
    "print(f\"\\nSố dòng ban đầu: {len(df_original):,}\")\n",
    "\n",
    "# Đếm số records có vote_average = 0\n",
    "records_with_zero = (df_original['vote_average'] == 0).sum()\n",
    "print(f\"Số records có vote_average = 0: {records_with_zero:,} ({records_with_zero/len(df_original)*100:.2f}%)\")\n",
    "\n",
    "# Xóa các records có vote_average = 0\n",
    "df_cleaned = df_original[df_original['vote_average'] != 0]\n",
    "print(f\"Số dòng sau khi xóa: {len(df_cleaned):,}\")\n",
    "print(f\"Số dòng đã xóa: {len(df_original) - len(df_cleaned):,}\")\n",
    "\n",
    "# Lưu file mới\n",
    "df_cleaned.to_csv('../data/cleaned/preprocessed_data_v2.csv', index=False)\n",
    "print(f\"\\nĐã lưu file mới: preprocessed_data_v2.csv\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed7507",
   "metadata": {},
   "source": [
    "Mục đích chính của cell này là để thống kê số lượng budget != 0 trong dataset, theo như tham khảo từ bài báo\n",
    "ArXiv:2405.11651\n",
    "Nhận thấy bài báo này có chủ đề và bài toán tương đồng (cùng là dự đoán phim), ở bài báo này là dự đoán doanh thu, nhận thấy paper này đáng để tham khảo ở Hình số 4 chọn ra K best features, hình features score, nhận thấy budget có điểm rất cao nên mình đã cân nhắc lọc ra các records có budget != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79cde148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "THỐNG KÊ BUDGET THEO NĂM\n",
      "================================================================================\n",
      "\n",
      "Khoảng thời gian: 2000 - 2021\n",
      "Tổng số năm: 12\n",
      "\n",
      " Năm  Tổng số phim  Phim có budget = 0  Phim có budget > 0  % budget = 0\n",
      "2000          3831                3491                 340         91.13\n",
      "2001          4067                3705                 362         91.10\n",
      "2002          4449                4044                 405         90.90\n",
      "2003          4678                4274                 404         91.36\n",
      "2004          4994                4488                 506         89.87\n",
      "2005          3083                2580                 503         83.68\n",
      "2016          6723                5907                 816         87.86\n",
      "2017          6833                6055                 778         88.61\n",
      "2018          6815                6087                 728         89.32\n",
      "2019          6758                6103                 655         90.31\n",
      "2020          6199                5660                 539         91.31\n",
      "2021            97                  62                  35         63.92\n",
      "\n",
      "================================================================================\n",
      "TỔNG KẾT\n",
      "================================================================================\n",
      "Tổng số phim: 58,527\n",
      "Tổng phim có budget = 0: 52,456 (89.63%)\n",
      "Tổng phim có budget > 0: 6,071 (10.37%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Thống kê số lượng phim có budget theo năm và số phim có budget = 0\n",
    "import pandas as pd\n",
    "\n",
    "# Đọc dataset\n",
    "df = pd.read_csv('../data/cleaned/preprocessed_data_v2.csv')\n",
    "\n",
    "# Chuyển release_date sang datetime và lấy năm\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['year'] = df['release_date'].dt.year\n",
    "\n",
    "# Loại bỏ các dòng không có năm hợp lệ\n",
    "df_with_year = df.dropna(subset=['year'])\n",
    "df_with_year['year'] = df_with_year['year'].astype(int)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"THỐNG KÊ BUDGET THEO NĂM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Tạo bảng thống kê\n",
    "year_stats = df_with_year.groupby('year').agg({\n",
    "    'budget': [\n",
    "        ('Tổng số phim', 'count'),\n",
    "        ('Phim có budget = 0', lambda x: (x == 0).sum()),\n",
    "        ('Phim có budget > 0', lambda x: (x > 0).sum())\n",
    "    ]\n",
    "}).reset_index()\n",
    "\n",
    "# Làm phẳng MultiIndex columns\n",
    "year_stats.columns = ['Năm', 'Tổng số phim', 'Phim có budget = 0', 'Phim có budget > 0']\n",
    "\n",
    "# Tính phần trăm phim có budget = 0\n",
    "year_stats['% budget = 0'] = (year_stats['Phim có budget = 0'] / year_stats['Tổng số phim'] * 100).round(2)\n",
    "\n",
    "# Sắp xếp theo năm\n",
    "year_stats = year_stats.sort_values('Năm')\n",
    "\n",
    "print(f\"\\nKhoảng thời gian: {year_stats['Năm'].min()} - {year_stats['Năm'].max()}\")\n",
    "print(f\"Tổng số năm: {len(year_stats)}\\n\")\n",
    "\n",
    "# Hiển thị bảng\n",
    "print(year_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TỔNG KẾT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Tổng số phim: {year_stats['Tổng số phim'].sum():,}\")\n",
    "print(f\"Tổng phim có budget = 0: {year_stats['Phim có budget = 0'].sum():,} ({year_stats['Phim có budget = 0'].sum() / year_stats['Tổng số phim'].sum() * 100:.2f}%)\")\n",
    "print(f\"Tổng phim có budget > 0: {year_stats['Phim có budget > 0'].sum():,} ({year_stats['Phim có budget > 0'].sum() / year_stats['Tổng số phim'].sum() * 100:.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f809b1",
   "metadata": {},
   "source": [
    "Kết quả là chỉ có khoảng 6k records có budget, vậy thì cần tìm cách để lấy thêm 4k records nữa để hoàn thành 10k records theo yêu cầu bài toán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f35abbb",
   "metadata": {},
   "source": [
    "**Vấn đề là cách lấy 4k còn lại từ dataset**  \n",
    "Dựa trên kết quả phân tích tầm quan trọng của đặc trưng (Feature Importance) từ nghiên cứu [ArXiv:2405.11651], budget được xác định là yếu tố then chốt (top K features) ảnh hưởng đến doanh thu.\n",
    "\n",
    "Trong tập dữ liệu hiện tại, các giá trị budget = 0 được xác định là dữ liệu bị khuyết (missing values) chứ không phải giá trị thực tế. Việc giữ lại các giá trị này sẽ gây nhiễu (noise) nghiêm trọng cho mô hình.\n",
    "\n",
    "Do đó, nhóm quyết định lọc bỏ các mẫu này để đảm bảo tính chính xác của dữ liệu đầu vào (Data Integrity), chấp nhận giới hạn phạm vi dự đoán của mô hình (Model Scope) chỉ trên các tác phẩm có dữ liệu sản xuất minh bạch, thay vì cố gắng dự đoán trên toàn bộ tập dữ liệu nhưng với độ tin cậy thấp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d80e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:50: SyntaxWarning: invalid escape sequence '\\G'\n",
      "<>:50: SyntaxWarning: invalid escape sequence '\\G'\n",
      "C:\\Users\\ad\\AppData\\Local\\Temp\\ipykernel_15720\\4256929852.py:50: SyntaxWarning: invalid escape sequence '\\G'\n",
      "  print(f\"\\Gold set already has {len(df_gold):,} records (≥ {target_size:,})\")\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GIAI ĐOẠN 1: LỰA CHỌN DỮ LIỆU - Phương pháp Điểm chất lượng (Quality Score)\n",
    "# =============================================================================\n",
    "# Lựa chọn các bản ghi chất lượng cao bằng cách sử dụng: quality_score = normalized(vote_count) + normalized(popularity)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def filter_gold_dataset(df, target_size=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    Lọc tập dữ liệu theo target_size bằng phương pháp lựa chọn theo Điểm chất lượng (Quality Score).\n",
    "\n",
    "    Chiến lược:\n",
    "    1. Giữ lại TẤT CẢ các bản ghi có budget > 0 (Gold Set - dữ liệu có độ tin cậy cao)\n",
    "    2. Chọn các bản ghi còn lại từ nhóm budget = 0 (Silver Set) bằng cách sử dụng quality_score\n",
    "    3. quality_score = normalized_vote_count + normalized_popularity\n",
    "\n",
    "    Tham số:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Tập dữ liệu đầu vào\n",
    "    target_size : int\n",
    "        Số lượng bản ghi mục tiêu (mặc định: 10000)\n",
    "    random_state : int\n",
    "        Số ngẫu nhiên (seed) để đảm bảo khả năng tái lập kết quả\n",
    "\n",
    "    Trả về:\n",
    "    --------\n",
    "    DataFrame : Tập dữ liệu đã được lọc với kích thước target_size\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"PHASE 1: DATA SELECTION (Quality Score Method)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Split into Gold (budget > 0) and Silver (budget = 0)\n",
    "    df_gold = df[df['budget'] > 0].copy()\n",
    "    df_silver = df[df['budget'] == 0].copy()\n",
    "    \n",
    "    print(f\"\\nDataset Split:\")\n",
    "    print(f\"   Gold (budget > 0):   {len(df_gold):,} records\")\n",
    "    print(f\"   Silver (budget = 0): {len(df_silver):,} records\")\n",
    "    \n",
    "    # Tính toán số lượng bản ghi Silver cần thiết\n",
    "    n_silver_needed = target_size - len(df_gold)\n",
    "    \n",
    "    if n_silver_needed <= 0:\n",
    "        print(f\"\\Gold set already has {len(df_gold):,} records (≥ {target_size:,})\")\n",
    "        print(f\"   Returning top {target_size:,} Gold records by quality_score\")\n",
    "        \n",
    "        # Áp dụng điểm chất lượng cho Gold và trả về N bản ghi đứng đầu\n",
    "        vote_norm = (df_gold['vote_count'] - df_gold['vote_count'].min()) / \\\n",
    "                    (df_gold['vote_count'].max() - df_gold['vote_count'].min() + 1e-10)\n",
    "        pop_norm = (df_gold['popularity'] - df_gold['popularity'].min()) / \\\n",
    "                   (df_gold['popularity'].max() - df_gold['popularity'].min() + 1e-10)\n",
    "        df_gold['quality_score'] = vote_norm + pop_norm\n",
    "        return df_gold.nlargest(target_size, 'quality_score').drop(columns=['quality_score'])\n",
    "    \n",
    "    print(f\"\\nNeed to select {n_silver_needed:,} records from Silver set\")\n",
    "    \n",
    "    # --- Lựa chọn theo Điểm chất lượng cho bộ Bạc (Silver Set) ---\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"Quality Score Selection\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Min-Max normalization\n",
    "    vote_norm = (df_silver['vote_count'] - df_silver['vote_count'].min()) / \\\n",
    "                (df_silver['vote_count'].max() - df_silver['vote_count'].min() + 1e-10)\n",
    "    pop_norm = (df_silver['popularity'] - df_silver['popularity'].min()) / \\\n",
    "               (df_silver['popularity'].max() - df_silver['popularity'].min() + 1e-10)\n",
    "    \n",
    "    # quality_score = vote_count + popularity (equal weights)\n",
    "    df_silver['quality_score'] = vote_norm + pop_norm\n",
    "    \n",
    "    # Select top N by quality_score\n",
    "    silver_selected = df_silver.nlargest(n_silver_needed, 'quality_score').drop(columns=['quality_score'])\n",
    "    \n",
    "    print(f\"   Selected: {len(silver_selected):,} records\")\n",
    "    print(f\"   vote_average: mean={silver_selected['vote_average'].mean():.3f}, std={silver_selected['vote_average'].std():.3f}\")\n",
    "    \n",
    "    # --- Combine and Finalize ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINALIZING DATASET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Combine Gold + Selected Silver\n",
    "    final_df = pd.concat([df_gold, silver_selected], ignore_index=True)\n",
    "    \n",
    "    # Shuffle\n",
    "    final_df = final_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Final stats\n",
    "    budget_positive = (final_df['budget'] > 0).sum()\n",
    "    budget_zero = (final_df['budget'] == 0).sum()\n",
    "    \n",
    "    print(f\"\\nFinal Dataset: {len(final_df):,} records\")\n",
    "    print(f\"   From Gold (budget > 0): {budget_positive:,} ({budget_positive/len(final_df)*100:.1f}%)\")\n",
    "    print(f\"   From Silver (budget = 0): {budget_zero:,} ({budget_zero/len(final_df)*100:.1f}%)\")\n",
    "    print(f\"   vote_average: mean={final_df['vote_average'].mean():.3f}, std={final_df['vote_average'].std():.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c970d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 58,527 records from preprocessed_data_v2.csv\n",
      "\n",
      "================================================================================\n",
      "PHASE 1: DATA SELECTION (Quality Score Method)\n",
      "================================================================================\n",
      "\n",
      "Dataset Split:\n",
      "   Gold (budget > 0):   6,071 records\n",
      "   Silver (budget = 0): 52,456 records\n",
      "\n",
      "Need to select 3,929 records from Silver set\n",
      "\n",
      "------------------------------------------------------------\n",
      "Quality Score Selection\n",
      "------------------------------------------------------------\n",
      "   Selected: 3,929 records\n",
      "   vote_average: mean=5.805, std=1.373\n",
      "\n",
      "============================================================\n",
      "FINALIZING DATASET\n",
      "============================================================\n",
      "\n",
      "Final Dataset: 10,000 records\n",
      "   From Gold (budget > 0): 6,071 (60.7%)\n",
      "   From Silver (budget = 0): 3,929 (39.3%)\n",
      "   vote_average: mean=5.880, std=1.512\n",
      "\n",
      "================================================================================\n",
      "\n",
      "PHASE 1 COMPLETE!\n",
      "Dataset size: 10,000 records\n",
      "Ready for Phase 2 (Train/Test Split)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 1 EXECUTION: Create 10k Dataset\n",
    "# =============================================================================\n",
    "\n",
    "# Read the dataset (after removing vote_average = 0 records)\n",
    "df_input = pd.read_csv('../data/cleaned/preprocessed_data_v2.csv')\n",
    "\n",
    "print(f\"Loaded: {len(df_input):,} records from preprocessed_data_v2.csv\\n\")\n",
    "\n",
    "# Apply the filter function\n",
    "df_10k = filter_gold_dataset(df_input, target_size=10000, random_state=42)\n",
    "df_10k.to_csv(\"../data/cleaned/data_da_resize.csv\", index=False)\n",
    "\n",
    "print(f\"\\nPHASE 1 COMPLETE!\")\n",
    "print(f\"Dataset size: {len(df_10k):,} records\")\n",
    "print(f\"Ready for Phase 2 (Train/Test Split)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072819d9",
   "metadata": {},
   "source": [
    "## Giai đoạn 2: Stratified Train/Test Split (Chia tập Huấn luyện/Kiểm thử phân tầng)\n",
    "\n",
    "**Tại sao phải chia tách TRƯỚC KHI xử lý dữ liệu thiếu (imputation)?**\n",
    "\n",
    "Rò rỉ dữ liệu (Data leakage) xảy ra khi thông tin từ tập test ảnh hưởng đến quá trình huấn luyện. Nếu chúng ta tính toán các giá trị median/mean trên toàn bộ tập dữ liệu trước khi chia, dữ liệu của tập test sẽ bị \"rò rỉ\" vào các giá trị imputation được sử dụng để huấn luyện.\n",
    "\n",
    "**Chiến lược phân tầng (Stratification Strategy):**\n",
    "- Tạo các nhóm (bins) từ `vote_average` (biến mục tiêu liên tục)\n",
    "- Sử dụng `StratifiedShuffleSplit` để duy trì phân phối dữ liệu\n",
    "- Tỷ lệ 80% Train / 20% Test\n",
    "\n",
    "**Kết quả mong đợi (Expected Output):**\n",
    "- `X_train`: 8,000 mẫu (chỉ bao gồm features)\n",
    "- `X_test`: 2,000 mẫu (chỉ bao gồm features)\n",
    "- `y_train`: 8,000 giá trị mục tiêu\n",
    "- `y_test`: 2,000 giá trị mục tiêu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d876902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 2: STRATIFIED TRAIN/TEST SPLIT\n",
      "================================================================================\n",
      "\n",
      "Loading data from: ../data/cleaned/data_da_resize.csv\n",
      "   Loaded: 10,000 records × 29 columns\n",
      "\n",
      "Configuration:\n",
      "   Input file: ../data/cleaned/data_da_resize.csv\n",
      "   Test size: 20%\n",
      "   Stratification bins: 10\n",
      "   Random state: 42\n",
      "\n",
      "------------------------------------------------------------\n",
      "Creating Stratification Bins from vote_average\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Bin distribution:\n",
      "      Bin 0: 126 records (1.3%)\n",
      "      Bin 1: 205 records (2.1%)\n",
      "      Bin 2: 281 records (2.8%)\n",
      "      Bin 3: 745 records (7.4%)\n",
      "      Bin 4: 1,437 records (14.4%)\n",
      "      Bin 5: 2,703 records (27.0%)\n",
      "      Bin 6: 2,918 records (29.2%)\n",
      "      Bin 7: 1,229 records (12.3%)\n",
      "      Bin 8: 172 records (1.7%)\n",
      "      Bin 9: 184 records (1.8%)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Splitting Data (80% Train / 20% Test)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Split Complete:\n",
      "   X_train: 8,000 samples\n",
      "   X_test:  2,000 samples\n",
      "   y_train: 8,000 values\n",
      "   y_test:  2,000 values\n",
      "\n",
      "------------------------------------------------------------\n",
      "Verifying Stratification Quality\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Set              Mean        Std      Min      Max\n",
      "   ----------------------------------------------\n",
      "   Full           5.8796     1.5120     0.50    10.00\n",
      "   Train          5.8775     1.5143     0.50    10.00\n",
      "   Test           5.8880     1.5030     0.50    10.00\n",
      "\n",
      "   KS Test (Train vs Test): stat=0.0119, p=0.9766\n",
      "Distributions are statistically similar\n",
      "\n",
      "------------------------------------------------------------\n",
      "Missing Values Status (BEFORE Imputation)\n",
      "------------------------------------------------------------\n",
      "\n",
      "NO IMPUTATION HAS BEEN APPLIED YET!\n",
      "   The following values need imputation:\n",
      "\n",
      "   Column         Train Missing    Test Missing\n",
      "   ------------------------------------------\n",
      "   budget                 3,157             772\n",
      "   runtime                  122              43\n",
      "\n",
      "================================================================================\n",
      "PHASE 2 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "NEXT: Phase 3 will apply LEAKAGE-FREE imputation\n",
      "   (Fitting ONLY on X_train, transforming both sets)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GIAI ĐOẠN 2: STRATIFIED TRAIN/TEST SPLIT (TRƯỚC KHI XỬ LÝ IMPUTATION!)\n",
    "# =============================================================================\n",
    "# QUAN TRỌNG: Chia dữ liệu TRƯỚC KHI imputation để ngăn chặn rò rỉ dữ liệu (data leakage).\n",
    "# Chúng ta sử dụng StratifiedShuffleSplit dựa trên các nhóm (bins) của vote_average.\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Cấu hình - Chỉnh sửa tại đây\n",
    "INPUT_FILE = \"../data/cleaned/data_da_resize.csv\"      # Thay đổi tên file input tại đây\n",
    "TEST_SIZE = 0.2                      # Tỷ lệ test set (20%)\n",
    "N_BINS = 10                          # Số bins để stratify\n",
    "TARGET_COL = 'vote_average'          # Tên cột target\n",
    "RANDOM_STATE = 42                    # Seed cho reproducibility\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2: STRATIFIED TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Tải dữ liệu từ file CSV\n",
    "print(f\"\\nLoading data from: {INPUT_FILE}\")\n",
    "df_input = pd.read_csv(INPUT_FILE)\n",
    "print(f\"   Loaded: {len(df_input):,} records × {df_input.shape[1]} columns\")\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"   Input file: {INPUT_FILE}\")\n",
    "print(f\"   Test size: {TEST_SIZE * 100:.0f}%\")\n",
    "print(f\"   Stratification bins: {N_BINS}\")\n",
    "print(f\"   Random state: {RANDOM_STATE}\")\n",
    "\n",
    "# Tạo các nhóm phân tầng (Stratification Bins)\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Creating Stratification Bins from vote_average\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Tạo các nhóm (bins) tạm thời để phân tầng\n",
    "df_input['_vote_bins'] = pd.cut(\n",
    "    df_input[TARGET_COL], \n",
    "    bins=N_BINS, \n",
    "    labels=False,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# Xử lý các giá trị NaN (không nên xảy ra, nhưng để đảm bảo an toàn)\n",
    "df_input['_vote_bins'] = df_input['_vote_bins'].fillna(N_BINS // 2).astype(int)\n",
    "\n",
    "print(f\"\\n   Bin distribution:\")\n",
    "for bin_idx, count in df_input['_vote_bins'].value_counts().sort_index().items():\n",
    "    print(f\"      Bin {bin_idx}: {count:,} records ({count/len(df_input)*100:.1f}%)\")\n",
    "\n",
    "# Thực hiện Stratified Split\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Splitting Data (80% Train / 20% Test)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Tách các đặc trưng (features) và biến mục tiêu (target)\n",
    "X = df_input.drop(columns=[TARGET_COL])\n",
    "y = df_input[TARGET_COL]\n",
    "stratify_col = df_input['_vote_bins']\n",
    "\n",
    "# Stratified Shuffle Split (Chia dữ liệu phân tầng ngẫu nhiên)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "for train_idx, test_idx in sss.split(X, stratify_col):\n",
    "    X_train = X.iloc[train_idx].copy()\n",
    "    X_test = X.iloc[test_idx].copy()\n",
    "    y_train = y.iloc[train_idx].copy()\n",
    "    y_test = y.iloc[test_idx].copy()\n",
    "\n",
    "# Xóa cột nhóm (bin) tạm thời\n",
    "X_train = X_train.drop(columns=['_vote_bins'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['_vote_bins'], errors='ignore')\n",
    "\n",
    "print(f\"\\nSplit Complete:\")\n",
    "print(f\"   X_train: {len(X_train):,} samples\")\n",
    "print(f\"   X_test:  {len(X_test):,} samples\")\n",
    "print(f\"   y_train: {len(y_train):,} values\")\n",
    "print(f\"   y_test:  {len(y_test):,} values\")\n",
    "\n",
    "# Kiểm tra chất lượng phân tầng\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Verifying Stratification Quality\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\\n   {'Set':<10} {'Mean':>10} {'Std':>10} {'Min':>8} {'Max':>8}\")\n",
    "print(f\"   {'-'*46}\")\n",
    "print(f\"   {'Full':<10} {y.mean():>10.4f} {y.std():>10.4f} {y.min():>8.2f} {y.max():>8.2f}\")\n",
    "print(f\"   {'Train':<10} {y_train.mean():>10.4f} {y_train.std():>10.4f} {y_train.min():>8.2f} {y_train.max():>8.2f}\")\n",
    "print(f\"   {'Test':<10} {y_test.mean():>10.4f} {y_test.std():>10.4f} {y_test.min():>8.2f} {y_test.max():>8.2f}\")\n",
    "\n",
    "# KS Test giữa tập train và tập test\n",
    "ks_stat, ks_pval = ks_2samp(y_train, y_test)\n",
    "print(f\"\\n   KS Test (Train vs Test): stat={ks_stat:.4f}, p={ks_pval:.4f}\")\n",
    "if ks_pval > 0.05:\n",
    "    print(f\"Distributions are statistically similar\")\n",
    "else:\n",
    "    print(f\"Some distribution difference detected\")\n",
    "\n",
    "# Kiểm tra các giá trị thiếu (Missing Values) TRƯỚC KHI xử lý Imputation\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Missing Values Status (BEFORE Imputation)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "print(f\"\\nNO IMPUTATION HAS BEEN APPLIED YET!\")\n",
    "print(f\"   The following values need imputation:\\n\")\n",
    "\n",
    "# Kiểm tra budget (0 = missing)\n",
    "train_budget_missing = (X_train['budget'] == 0).sum()\n",
    "test_budget_missing = (X_test['budget'] == 0).sum()\n",
    "\n",
    "# Kiểm tra runtime (0 hoặc NaN = missing)\n",
    "train_runtime_missing = ((X_train['runtime'] == 0) | X_train['runtime'].isna()).sum()\n",
    "test_runtime_missing = ((X_test['runtime'] == 0) | X_test['runtime'].isna()).sum()\n",
    "\n",
    "print(f\"   {'Column':<12} {'Train Missing':>15} {'Test Missing':>15}\")\n",
    "print(f\"   {'-'*42}\")\n",
    "print(f\"   {'budget':<12} {train_budget_missing:>15,} {test_budget_missing:>15,}\")\n",
    "print(f\"   {'runtime':<12} {train_runtime_missing:>15,} {test_runtime_missing:>15,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNEXT: Phase 3 will apply LEAKAGE-FREE imputation\")\n",
    "print(\"   (Fitting ONLY on X_train, transforming both sets)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce745e",
   "metadata": {},
   "source": [
    "## Giai đoạn 3: Leakage-Free Cleaning & Imputation (Làm sạch & Xử lý giá trị thiếu không gây rò rỉ)\n",
    "\n",
    "**Vấn đề nguyên bản (Data Leakage):**\n",
    "```python\n",
    "# CODE CŨ - LEAKAGE!\n",
    "runtime_median = df['runtime'].median()  # ← Được tính toán trên TOÀN BỘ dataset\n",
    "df['runtime'] = df['runtime'].fillna(runtime_median)\n",
    "```\n",
    "\n",
    "**Cách khắc phục:**\n",
    "```python\n",
    "# CODE MỚI - KHÔNG LEAKAGE\n",
    "runtime_median = X_train['runtime'].median()  # ← Chỉ được tính toán trên tập TRAIN\n",
    "X_train['runtime'] = X_train['runtime'].fillna(runtime_median)\n",
    "X_test['runtime'] = X_test['runtime'].fillna(runtime_median)  # ← Sử dụng median của tập TRAIN\n",
    "```\n",
    "\n",
    "Ô lệnh này so sánh hai phương pháp imputation:\n",
    "1. **Simple Median** (nhanh, dùng làm baseline)\n",
    "2. **IterativeImputer với RandomForest** (dựa trên mô hình, giúp nắm bắt các mối quan hệ giữa các biến)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf3d0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 3: LEAKAGE-FREE CLEANING & IMPUTATION\n",
      "================================================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 1: Categorical Imputation (Static Values)\n",
      "------------------------------------------------------------\n",
      "   genres: filled 119 NaN with 'Unknown'\n",
      "   keywords: filled 2805 NaN with 'Unknown'\n",
      "   cast_top5: filled 81 NaN with 'Unknown'\n",
      "   directors: filled 65 NaN with 'Unknown'\n",
      "   production_companies: filled 1066 NaN with 'Unknown'\n",
      "   production_countries: filled 606 NaN with 'Unknown'\n",
      "   spoken_languages: filled 361 NaN with 'Unknown'\n",
      "   collection_id: filled 8664 NaN with '-1'\n",
      "   certification_US: filled 6467 NaN with 'NR'\n",
      "   tagline: filled 4456 NaN with ''\n",
      "   overview: filled 85 NaN with ''\n",
      "\n",
      "   Categorical imputation complete (no leakage - static values)\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 2: Numerical Imputation (Fit on TRAIN only)\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Converting 0 → NaN for imputation...\n",
      "      runtime: Train 122 zeros → NaN, Test 43 zeros → NaN\n",
      "      budget: Train 3157 zeros → NaN, Test 772 zeros → NaN\n",
      "\n",
      "   Reference (valid values in TRAIN):\n",
      "      runtime: n=7,878, median=95.0\n",
      "      budget:  n=4,843, median=2,500,000\n",
      "\n",
      "------------------------------------------------------------\n",
      "METHOD A: Simple Median Imputation\n",
      "------------------------------------------------------------\n",
      "\n",
      "   # Fitting median on Train only (LEAKAGE PREVENTION)\n",
      "   runtime_median (from train): 95.0\n",
      "   budget_median (from train):  2,500,000\n",
      "\n",
      "    Method A complete\n",
      "      Train runtime: mean=95.1, std=32.4\n",
      "      Train budget:  mean=10,192,286, std=26,079,777\n",
      "\n",
      "------------------------------------------------------------\n",
      "METHOD B: IterativeImputer (RandomForest)\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Features for imputation: ['runtime', 'budget', 'popularity', 'vote_count', 'revenue']\n",
      "\n",
      "   # Fitting IterativeImputer on Train only (LEAKAGE PREVENTION)\n",
      "\n",
      "    Method B complete\n",
      "      Train runtime: mean=94.8, std=32.6\n",
      "      Train budget:  mean=11,100,691, std=26,105,895\n",
      "\n",
      "============================================================\n",
      "STEP 3: Comparing Imputation Methods\n",
      "============================================================\n",
      "\n",
      " Imputation Quality Comparison:\n",
      "   (Variance Ratio: closer to 1.0 = better distribution preservation)\n",
      "\n",
      "   Method          Column      Mean Diff %    Var Ratio\n",
      "   --------------------------------------------------\n",
      "   Median          runtime           0.00%       0.9847\n",
      "   Median          budget           32.97%       0.6417\n",
      "   Iterative (RF)  runtime           0.31%       0.9973\n",
      "   Iterative (RF)  budget           27.00%       0.6430\n",
      "\n",
      " Z-Score Analysis (outliers with |z| > 3):\n",
      "   runtime:\n",
      "      Median method: 26 outliers\n",
      "      Iterative method: 26 outliers\n",
      "   budget:\n",
      "      Median method: 198 outliers\n",
      "      Iterative method: 199 outliers\n",
      "\n",
      "------------------------------------------------------------\n",
      "DECISION: Selecting Best Imputation Method\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Average distance from perfect variance ratio (1.0):\n",
      "      Median method:    0.1868\n",
      "      Iterative method: 0.1799\n",
      "\n",
      "   SELECTED: Iterative (RandomForest) - better variance preservation\n",
      "\n",
      "------------------------------------------------------------\n",
      "STEP 5: Final Cleanup\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Final NaN check:\n",
      "      X_train_final: 30668 NaN remaining\n",
      "      X_test_final:  7671 NaN remaining\n",
      "   Columns with remaining NaN: ['collection_name', 'facebook_id', 'imdb_id', 'instagram_id', 'trailer_key', 'twitter_id']\n",
      "\n",
      "================================================================================\n",
      "PHASE 3 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "   Imputation Method Used: Iterative\n",
      "   X_train_final: (8000, 28)\n",
      "   X_test_final:  (2000, 28)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GIAI ĐOẠN 3: LEAKAGE-FREE CLEANING & IMPUTATION (LÀM SẠCH & XỬ LÝ GIÁ TRỊ THIẾU KHÔNG GÂY RÒ RỈ)\n",
    "# =============================================================================\n",
    "# Phiên bản tái cấu trúc này chỉ thực hiện Fit (khớp dữ liệu) trên X_train và Transform (biến đổi) trên cả hai tập dữ liệu.\n",
    "# Các giá trị cần điền ban đầu được giữ nguyên: 'NR', -1, '', 'Unknown', v.v.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import zscore\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 3: LEAKAGE-FREE CLEANING & IMPUTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# BƯỚC 1: Categorical Imputation (Điền dữ liệu phân loại - Giá trị tĩnh - Không rủi ro rò rỉ)\n",
    "# =============================================================================\n",
    "# Các bước này sử dụng giá trị cố định, vì vậy có thể áp dụng an toàn mà không cần bước fitting.\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 1: Categorical Imputation (Static Values)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Logic điền giá trị gốc được giữ nguyên chính xác:\n",
    "CATEGORICAL_FILLS = {\n",
    "    'genres': 'Unknown',\n",
    "    'keywords': 'Unknown', \n",
    "    'cast_top5': 'Unknown',\n",
    "    'directors': 'Unknown',\n",
    "    'production_companies': 'Unknown',\n",
    "    'production_countries': 'Unknown',\n",
    "    'spoken_languages': 'Unknown',\n",
    "    'original_language': 'Unknown',\n",
    "    'collection_id': -1,          # Phim lẻ (standalone film)\n",
    "    'certification_US': 'NR',     # Chưa phân loại (Not Rated)\n",
    "    'tagline': '',                # Không có slogan\n",
    "    'overview': ''                # Không có mô tả\n",
    "}\n",
    "\n",
    "for col, fill_value in CATEGORICAL_FILLS.items():\n",
    "    if col in X_train.columns:\n",
    "        train_missing = X_train[col].isna().sum()\n",
    "        test_missing = X_test[col].isna().sum()\n",
    "        \n",
    "        X_train[col] = X_train[col].fillna(fill_value)\n",
    "        X_test[col] = X_test[col].fillna(fill_value)\n",
    "        \n",
    "        if train_missing > 0 or test_missing > 0:\n",
    "            print(f\"   {col}: filled {train_missing + test_missing} NaN with '{fill_value}'\")\n",
    "\n",
    "print(\"\\n   Categorical imputation complete (no leakage - static values)\")\n",
    "\n",
    "# =============================================================================\n",
    "# BƯỚC 2: Numerical Imputation (LÀM SẠCH KHÔNG RÒ RỈ - Fit trên Train)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 2: Numerical Imputation (Fit on TRAIN only)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Các cột cần điền giá trị số (0 = thiếu)\n",
    "NUMERIC_IMPUTE_COLS = ['runtime', 'budget']\n",
    "\n",
    "# Chuyển 0 thành NaN cho các cột này (0 nghĩa là dữ liệu thiếu)\n",
    "print(\"\\n   Converting 0 → NaN for imputation...\")\n",
    "for col in NUMERIC_IMPUTE_COLS:\n",
    "    train_zeros = (X_train[col] == 0).sum()\n",
    "    test_zeros = (X_test[col] == 0).sum()\n",
    "    \n",
    "    X_train.loc[X_train[col] == 0, col] = np.nan\n",
    "    X_test.loc[X_test[col] == 0, col] = np.nan\n",
    "    \n",
    "    print(f\"      {col}: Train {train_zeros} zeros → NaN, Test {test_zeros} zeros → NaN\")\n",
    "\n",
    "# Lưu phân phối tham chiếu (giá trị hợp lệ không thiếu trong TRAIN)\n",
    "train_runtime_valid = X_train[X_train['runtime'].notna()]['runtime']\n",
    "train_budget_valid = X_train[X_train['budget'].notna()]['budget']\n",
    "\n",
    "print(f\"\\n   Reference (valid values in TRAIN):\")\n",
    "print(f\"      runtime: n={len(train_runtime_valid):,}, median={train_runtime_valid.median():.1f}\")\n",
    "print(f\"      budget:  n={len(train_budget_valid):,}, median={train_budget_valid.median():,.0f}\")\n",
    "\n",
    "# PHƯƠNG PHÁP A: Điền giá trị trung vị đơn giản (Simple Median Imputation)\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"METHOD A: Simple Median Imputation\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# QUAN TRỌNG: Chỉ Fit median trên tập TRAIN!\n",
    "print(\"\\n   # Fitting median on Train only (LEAKAGE PREVENTION)\")\n",
    "\n",
    "# Calculate medians from TRAIN set only\n",
    "runtime_median_train = X_train['runtime'].median()\n",
    "budget_median_train = X_train['budget'].median()\n",
    "\n",
    "print(f\"   runtime_median (from train): {runtime_median_train:.1f}\")\n",
    "print(f\"   budget_median (from train):  {budget_median_train:,.0f}\")\n",
    "\n",
    "# Apply to both sets\n",
    "X_train_median = X_train.copy()\n",
    "X_test_median = X_test.copy()\n",
    "\n",
    "X_train_median['runtime'] = X_train_median['runtime'].fillna(runtime_median_train)\n",
    "X_train_median['budget'] = X_train_median['budget'].fillna(budget_median_train)\n",
    "\n",
    "# IMPORTANT: Use TRAIN median for TEST set too!\n",
    "X_test_median['runtime'] = X_test_median['runtime'].fillna(runtime_median_train)\n",
    "X_test_median['budget'] = X_test_median['budget'].fillna(budget_median_train)\n",
    "\n",
    "print(f\"\\n    Method A complete\")\n",
    "print(f\"      Train runtime: mean={X_train_median['runtime'].mean():.1f}, std={X_train_median['runtime'].std():.1f}\")\n",
    "print(f\"      Train budget:  mean={X_train_median['budget'].mean():,.0f}, std={X_train_median['budget'].std():,.0f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PHƯƠNG PHÁP B: IterativeImputer (Dựa trên Mô hình RandomForest)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"METHOD B: IterativeImputer (RandomForest)\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Các cột sử dụng cho phương pháp điền giá trị dựa trên mô hình\n",
    "ITER_FEATURES = ['runtime', 'budget', 'popularity', 'vote_count', 'revenue']\n",
    "iter_features_available = [f for f in ITER_FEATURES if f in X_train.columns]\n",
    "\n",
    "print(f\"\\n   Features for imputation: {iter_features_available}\")\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X_train_iter_input = X_train[iter_features_available].copy()\n",
    "X_test_iter_input = X_test[iter_features_available].copy()\n",
    "\n",
    "# Khởi tạo IterativeImputer\n",
    "print(f\"\\n   # Fitting IterativeImputer on Train only (LEAKAGE PREVENTION)\")\n",
    "\n",
    "iter_imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    max_iter=10,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# CHỈ FIT TRÊN TẬP TRAIN!\n",
    "iter_imputer.fit(X_train_iter_input)\n",
    "\n",
    "# Biến đổi cả hai tập dữ liệu bằng imputer đã được fit trên tập train\n",
    "X_train_iter_output = pd.DataFrame(\n",
    "    iter_imputer.transform(X_train_iter_input),\n",
    "    columns=iter_features_available,\n",
    "    index=X_train_iter_input.index\n",
    ")\n",
    "\n",
    "X_test_iter_output = pd.DataFrame(\n",
    "    iter_imputer.transform(X_test_iter_input),\n",
    "    columns=iter_features_available,\n",
    "    index=X_test_iter_input.index\n",
    ")\n",
    "\n",
    "# Tạo bản sao đầy đủ với các giá trị đã được điền\n",
    "X_train_iter = X_train.copy()\n",
    "X_test_iter = X_test.copy()\n",
    "\n",
    "for col in NUMERIC_IMPUTE_COLS:\n",
    "    X_train_iter[col] = X_train_iter_output[col]\n",
    "    X_test_iter[col] = X_test_iter_output[col]\n",
    "\n",
    "print(f\"\\n    Method B complete\")\n",
    "print(f\"      Train runtime: mean={X_train_iter['runtime'].mean():.1f}, std={X_train_iter['runtime'].std():.1f}\")\n",
    "print(f\"      Train budget:  mean={X_train_iter['budget'].mean():,.0f}, std={X_train_iter['budget'].std():,.0f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# BƯỚC 3: So sánh các phương pháp (Phân tích Z-Score & Phương sai)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Comparing Imputation Methods\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def evaluate_imputation(original_valid, imputed_all, col_name, method_name):\n",
    "    \"\"\"So sánh phân phối sau khi được điền giá trị (imputed distribution) với các giá trị hợp lệ ban đầu.\"\"\"\n",
    "    orig_mean = original_valid.mean()\n",
    "    orig_std = original_valid.std()\n",
    "    orig_var = original_valid.var()\n",
    "    \n",
    "    imp_mean = imputed_all.mean()\n",
    "    imp_std = imputed_all.std()\n",
    "    imp_var = imputed_all.var()\n",
    "    \n",
    "    # Tỷ lệ phương sai (1.0 = khớp hoàn hảo)\n",
    "    var_ratio = imp_var / orig_var if orig_var > 0 else 0\n",
    "    \n",
    "    # Phần trăm sai lệch trung bình (Mean percentage difference)\n",
    "    mean_diff_pct = abs(imp_mean - orig_mean) / orig_mean * 100 if orig_mean != 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'method': method_name,\n",
    "        'column': col_name,\n",
    "        'mean_diff_pct': mean_diff_pct,\n",
    "        'var_ratio': var_ratio,\n",
    "        'imp_std': imp_std,\n",
    "        'orig_std': orig_std\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# Đánh giá Phương pháp A\n",
    "results.append(evaluate_imputation(train_runtime_valid, X_train_median['runtime'], 'runtime', 'Median'))\n",
    "results.append(evaluate_imputation(train_budget_valid, X_train_median['budget'], 'budget', 'Median'))\n",
    "\n",
    "# Đánh giá Phương pháp B\n",
    "results.append(evaluate_imputation(train_runtime_valid, X_train_iter['runtime'], 'runtime', 'Iterative (RF)'))\n",
    "results.append(evaluate_imputation(train_budget_valid, X_train_iter['budget'], 'budget', 'Iterative (RF)'))\n",
    "\n",
    "print(f\"\\n Imputation Quality Comparison:\")\n",
    "print(f\"   (Variance Ratio: closer to 1.0 = better distribution preservation)\")\n",
    "print(f\"\\n   {'Method':<15} {'Column':<10} {'Mean Diff %':>12} {'Var Ratio':>12}\")\n",
    "print(f\"   {'-'*50}\")\n",
    "\n",
    "for r in results:\n",
    "    print(f\"   {r['method']:<15} {r['column']:<10} {r['mean_diff_pct']:>11.2f}% {r['var_ratio']:>12.4f}\")\n",
    "\n",
    "# Z-Score Analysis\n",
    "print(f\"\\n Z-Score Analysis (outliers with |z| > 3):\")\n",
    "\n",
    "for col in NUMERIC_IMPUTE_COLS:\n",
    "    z_median = zscore(X_train_median[col].dropna())\n",
    "    z_iter = zscore(X_train_iter[col].dropna())\n",
    "    \n",
    "    outliers_median = (np.abs(z_median) > 3).sum()\n",
    "    outliers_iter = (np.abs(z_iter) > 3).sum()\n",
    "    \n",
    "    print(f\"   {col}:\")\n",
    "    print(f\"      Median method: {outliers_median} outliers\")\n",
    "    print(f\"      Iterative method: {outliers_iter} outliers\")\n",
    "\n",
    "# =============================================================================\n",
    "# BƯỚC 4: Chọn Phương pháp Tốt nhất\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"DECISION: Selecting Best Imputation Method\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Calculate average variance ratio distance from 1.0\n",
    "median_results = [r for r in results if r['method'] == 'Median']\n",
    "iter_results = [r for r in results if r['method'] == 'Iterative (RF)']\n",
    "\n",
    "median_var_dist = np.mean([abs(1.0 - r['var_ratio']) for r in median_results])\n",
    "iter_var_dist = np.mean([abs(1.0 - r['var_ratio']) for r in iter_results])\n",
    "\n",
    "print(f\"\\n   Average distance from perfect variance ratio (1.0):\")\n",
    "print(f\"      Median method:    {median_var_dist:.4f}\")\n",
    "print(f\"      Iterative method: {iter_var_dist:.4f}\")\n",
    "\n",
    "if iter_var_dist < median_var_dist:\n",
    "    BEST_METHOD = \"Iterative\"\n",
    "    X_train_final = X_train_iter.copy()\n",
    "    X_test_final = X_test_iter.copy()\n",
    "    print(f\"\\n   SELECTED: Iterative (RandomForest) - better variance preservation\")\n",
    "else:\n",
    "    BEST_METHOD = \"Median\"\n",
    "    X_train_final = X_train_median.copy()\n",
    "    X_test_final = X_test_median.copy()\n",
    "    print(f\"\\n   SELECTED: Median - simpler and sufficient\")\n",
    "\n",
    "# =============================================================================\n",
    "# BƯỚC 5: Làm sạch lần cuối (Các giá trị NaN còn lại → 0 cho dữ liệu số)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"STEP 5: Final Cleanup\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Điền 0 vào tất cả các giá trị numeric NaN còn lại\n",
    "numeric_cols = X_train_final.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if col not in NUMERIC_IMPUTE_COLS:  # Already handled above\n",
    "        train_nan = X_train_final[col].isna().sum()\n",
    "        test_nan = X_test_final[col].isna().sum()\n",
    "        if train_nan > 0 or test_nan > 0:\n",
    "            X_train_final[col] = X_train_final[col].fillna(0)\n",
    "            X_test_final[col] = X_test_final[col].fillna(0)\n",
    "            print(f\"   {col}: filled {train_nan + test_nan} remaining NaN with 0\")\n",
    "\n",
    "# Xác nhận không còn giá trị NaN nào sót lại\n",
    "train_nan_total = X_train_final.isna().sum().sum()\n",
    "test_nan_total = X_test_final.isna().sum().sum()\n",
    "\n",
    "print(f\"\\n   Final NaN check:\")\n",
    "print(f\"      X_train_final: {train_nan_total} NaN remaining\")\n",
    "print(f\"      X_test_final:  {test_nan_total} NaN remaining\")\n",
    "\n",
    "if train_nan_total == 0 and test_nan_total == 0:\n",
    "    print(f\"   All missing values handled!\")\n",
    "else:\n",
    "    nan_cols = X_train_final.columns[X_train_final.isna().any()].tolist()\n",
    "    print(f\"   Columns with remaining NaN: {nan_cols}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 3 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n   Imputation Method Used: {BEST_METHOD}\")\n",
    "print(f\"   X_train_final: {X_train_final.shape}\")\n",
    "print(f\"   X_test_final:  {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1fc6095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 4: SAVE FINAL DATASETS\n",
      "================================================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Preparing Final DataFrames\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Train: 8,000 rows × 29 columns\n",
      "   Test:  2,000 rows × 29 columns\n",
      "\n",
      "------------------------------------------------------------\n",
      "Final Verification\n",
      "------------------------------------------------------------\n",
      "\n",
      "   Duplicate rows:\n",
      "      Train: 0\n",
      "      Test:  0\n",
      "\n",
      "   Target (vote_average) distribution:\n",
      "      Set            Mean        Std      Min      Max\n",
      "      --------------------------------------------\n",
      "      Train        5.8775     1.5143     0.50    10.00\n",
      "      Test         5.8880     1.5030     0.50    10.00\n",
      "\n",
      "   KS Test (Train vs Test): stat=0.0119, p=0.9766\n",
      "\n",
      "   Imputed columns verification:\n",
      "      runtime: Train(zeros=0, nan=0), Test(zeros=0, nan=0)\n",
      "      budget: Train(zeros=0, nan=0), Test(zeros=0, nan=0)\n",
      "\n",
      "------------------------------------------------------------\n",
      "Saving Files\n",
      "------------------------------------------------------------\n",
      "\n",
      "    ../data/cleaned/train_raw.csv: 8,000 rows saved\n",
      "    ../data/cleaned/test_raw.csv:  2,000 rows saved\n",
      "\n",
      "================================================================================\n",
      "DATA LEAKAGE PREVENTION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "   LEAKAGE-FREE CHECKLIST:\n",
      "\n",
      "   Phase 1: Data Selection\n",
      "   └─ KS Test comparison between Quality Score vs Random Sampling\n",
      "   └─ No target leakage (selection based on budget, vote_count, popularity)\n",
      "\n",
      "   Phase 2: Train/Test Split\n",
      "   └─ Split performed BEFORE any imputation\n",
      "   └─ Stratified by vote_average bins\n",
      "   └─ 80/20 ratio maintained\n",
      "\n",
      "   Phase 3: Imputation\n",
      "   └─ Categorical fills: Static values (no fitting needed)\n",
      "   └─ Numerical fills: Median/IterativeImputer FIT ON TRAIN ONLY\n",
      "   └─ Test set transformed using TRAIN-fitted values\n",
      "\n",
      "   Phase 4: Save\n",
      "   └─ Separate train/test files\n",
      "   └─ No index columns saved\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "  QUICK START FOR MODELING:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load preprocessed data\n",
      "train_df = pd.read_csv('train_final.csv')\n",
      "test_df = pd.read_csv('test_final.csv')\n",
      "\n",
      "# Separate features and target\n",
      "X_train = train_df.drop('vote_average', axis=1)\n",
      "y_train = train_df['vote_average']\n",
      "\n",
      "X_test = test_df.drop('vote_average', axis=1)\n",
      "y_test = test_df['vote_average']\n",
      "\n",
      "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
      "# Ready for modeling!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GIAI ĐOẠN 4: LƯU TẬP DỮ LIỆU CUỐI CÙNG\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 4: SAVE FINAL DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Output file names\n",
    "OUTPUT_TRAIN = \"../data/cleaned/train_raw.csv\"\n",
    "OUTPUT_TEST = \"../data/cleaned/test_raw.csv\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Thêm cột Target trở lại vào các DataFrame\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Preparing Final DataFrames\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Tạo DataFrame train/test cuối cùng bao gồm cả cột target\n",
    "train_df = X_train_final.copy()\n",
    "test_df = X_test_final.copy()\n",
    "\n",
    "train_df['vote_average'] = y_train.values\n",
    "test_df['vote_average'] = y_test.values\n",
    "\n",
    "print(f\"\\n   Train: {train_df.shape[0]:,} rows × {train_df.shape[1]} columns\")\n",
    "print(f\"   Test:  {test_df.shape[0]:,} rows × {test_df.shape[1]} columns\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Kiểm tra cuối cùng\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Final Verification\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Kiểm tra các giá trị trùng lặp (duplicates)\n",
    "train_dups = train_df.duplicated().sum()\n",
    "test_dups = test_df.duplicated().sum()\n",
    "\n",
    "print(f\"\\n   Duplicate rows:\")\n",
    "print(f\"      Train: {train_dups}\")\n",
    "print(f\"      Test:  {test_dups}\")\n",
    "\n",
    "# Kiểm tra phân phối của biến mục tiêu\n",
    "print(f\"\\n   Target (vote_average) distribution:\")\n",
    "print(f\"      {'Set':<8} {'Mean':>10} {'Std':>10} {'Min':>8} {'Max':>8}\")\n",
    "print(f\"      {'-'*44}\")\n",
    "print(f\"      {'Train':<8} {train_df['vote_average'].mean():>10.4f} {train_df['vote_average'].std():>10.4f} {train_df['vote_average'].min():>8.2f} {train_df['vote_average'].max():>8.2f}\")\n",
    "print(f\"      {'Test':<8} {test_df['vote_average'].mean():>10.4f} {test_df['vote_average'].std():>10.4f} {test_df['vote_average'].min():>8.2f} {test_df['vote_average'].max():>8.2f}\")\n",
    "\n",
    "# KS test cho các phân phối cuối cùng\n",
    "ks_final, p_final = ks_2samp(train_df['vote_average'], test_df['vote_average'])\n",
    "print(f\"\\n   KS Test (Train vs Test): stat={ks_final:.4f}, p={p_final:.4f}\")\n",
    "\n",
    "# Kiểm tra các cột quan trọng vừa được điền dữ liệu\n",
    "print(f\"\\n   Imputed columns verification:\")\n",
    "for col in ['runtime', 'budget']:\n",
    "    train_zeros = (train_df[col] == 0).sum()\n",
    "    test_zeros = (test_df[col] == 0).sum()\n",
    "    train_nan = train_df[col].isna().sum()\n",
    "    test_nan = test_df[col].isna().sum()\n",
    "    print(f\"      {col}: Train(zeros={train_zeros}, nan={train_nan}), Test(zeros={test_zeros}, nan={test_nan})\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Lưu các tập dữ liệu\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Saving Files\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Lưu dữ liệu không kèm theo index\n",
    "train_df.to_csv(OUTPUT_TRAIN, index=False)\n",
    "test_df.to_csv(OUTPUT_TEST, index=False)\n",
    "\n",
    "print(f\"\\n    {OUTPUT_TRAIN}: {len(train_df):,} rows saved\")\n",
    "print(f\"    {OUTPUT_TEST}:  {len(test_df):,} rows saved\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Tóm tắt xác nhận không rò rỉ dữ liệu\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA LEAKAGE PREVENTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "   LEAKAGE-FREE CHECKLIST:\n",
    "\n",
    "   Phase 1: Data Selection\n",
    "   └─ KS Test comparison between Quality Score vs Random Sampling\n",
    "   └─ No target leakage (selection based on budget, vote_count, popularity)\n",
    "\n",
    "   Phase 2: Train/Test Split\n",
    "   └─ Split performed BEFORE any imputation\n",
    "   └─ Stratified by vote_average bins\n",
    "   └─ 80/20 ratio maintained\n",
    "\n",
    "   Phase 3: Imputation\n",
    "   └─ Categorical fills: Static values (no fitting needed)\n",
    "   └─ Numerical fills: Median/IterativeImputer FIT ON TRAIN ONLY\n",
    "   └─ Test set transformed using TRAIN-fitted values\n",
    "\n",
    "   Phase 4: Save\n",
    "   └─ Separate train/test files\n",
    "   └─ No index columns saved\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Khởi động nhanh quy trình huấn luyện mô hình\n",
    "print(\"\"\"\n",
    "  QUICK START FOR MODELING:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load preprocessed data\n",
    "train_df = pd.read_csv('train_final.csv')\n",
    "test_df = pd.read_csv('test_final.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('vote_average', axis=1)\n",
    "y_train = train_df['vote_average']\n",
    "\n",
    "X_test = test_df.drop('vote_average', axis=1)\n",
    "y_test = test_df['vote_average']\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "# Ready for modeling!\n",
    "```\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
